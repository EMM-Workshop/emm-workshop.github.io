<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
  <meta name="keywords"
    content="EMM workshop">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />


  <link rel="stylesheet" href="main.css" type="text/css" />
  <link rel="stylesheet" href="font-awesome/css/font-awesome.min.css">
  <!--- <title></title> --->
  <title>EMM Workshop</title>
  <!-- MathJax -->

  <!-- End MathJax -->
</head>

<body>
  <div id="main-container">
    <div id="header-container">
      <div id="header">
        <div id="header-icon-text-container">
          <div id="header-text-container">
            <nav class="style1">
              <ul id="outer_list">
                <li id="outer_li_year"><a id="current_year" href="#">2026<span id="arrow"></span></a>
                  <ul id="top_list">
                    <li id="style2"><a id="style3" href="workshop2026.html">2026</a></li>
                    </li>
                  </ul>
                </li>

                <li id="outer_li"><a id="workshop_link" href="#">Workshop</a>
                </li>

              </ul>
            </nav>
          </div>
        </div>

      </div>
      <div id="layout-content">
        <div id="text-img-container">
          <div id="img-container">
            <a href="https://emm-workshop.github.io/"><img src="./logos/emm.png" alt="EMM" width="100%" /></a>
          </div>
          <div id="text-container"></div>
        </div>
        <p>
        <div id="beamer">
          <beam>
            Efficient Methods for Multimodal Models (EMM)
          </beam></br>
          <beams>
            in conjunction with ICPR 2026</br>
          </beams>
        </div>

        <br>
        <div id="menu-container">
          <div id="menu-item"><a id="style6" href="#overview">Overview</a></div>
          <div id="menu-item"><a id="style6" href="#schedule">Schedule</a></div>
          <div id="menu-item"><a id="style6" href="#papers">Papers</a></div>
          <div id="menu-item"><a id="style6" href="#organizers">Organizers</a></div>
          <div id="menu-item"><a id="style6" href="#contact">Contact</a></div>
        </div>
        <br>
        </p>


        <h1 id="overview">Overview </h1>
        <font size="5">
          Welcome to our Efficient Methods for Multimodal Models (EMM) workshop.
        </font>
        </br>
        </br>
        <p>
          This workshop will bring together researchers focused on developing efficient inferring, training, and fine-tuning methods, as well as model architectures and applications for multimodal models and tasks. With extensive applications in image and video understanding, as well as in image, video, and text generation, multimodal models have become increasingly prominent and transformative in the fields of pattern recognition and computer vision. Alongside the exponential growth of their parameters, there is an urgent need to investigate efficient learning and deployment methods for these models and tasks. This workshop will provide a unique platform for researchers and practitioners to collaborate on solutions, ultimately enhancing the efficiency and application of multimodal models
        </p>

        <p>
          The topics will include efficient inferring methods and model architecture design for multimodal models, e.g., compression, quantization, distillation, and efficient architecture, as well as efficient learning methods, e.g., training and finetuning methods for multimodal tasks. Additionally, we will explore related applications, such as efficient multimodal generative and editing models, practical multimodal applications, and deploying multimodal models on lowpower devices. Relevant topics include:
        </p>

        <h2>Topics</h2>


        We will cover all hand-related topics. The relevant topics include and not limited to:

        <ul id="topicstyle1">
          <li id="topicstyle2">Compression, quantization, conditional compute, pruning, and distillation of multi-modal models</li>
          <li id="topicstyle2">Efficient sampling of multimodal diffusion models, e.g., step distillation and consistency models </li>
          <li id="topicstyle2">Efficient training/finetuning of multi-modal models, e.g., low-rank adaptation</li>
          <li id="topicstyle2">Efficient LLM/LVLM/MLLM in multi-modal tasks, e.g., token pruning and merging</li>
          <li id="topicstyle2">Imitation learning, reinforcement learning</li>
          <li id="topicstyle2">Efficient multi-/crossmodal learning</li>
          <li id="topicstyle2">Efficient multimodal applications (e.g., drone vision, autonomous driving, etc.)</li>
          <li id="topicstyle2">Efficient multimodal generative and editing models and sensors, e.g., for vision, language, audio and 3D objects</li>
          <li id="topicstyle2">Efficient self-/un-/weakly-supervised learning for multimodal data</li>
          <li id="topicstyle2">Efficient image, video and audio synthesis by multimodal data</li>
          <li id="topicstyle2">Deploying multimodal models on low power devices e.g., smartphone</li>
        </ul>


        <h1 id="schedule">Schedule</h1>
        <p>TBD</p>

        <h1 id="schedule">Schedule</h1>
        <p>TBD</p>

        <h1 id="papers">Papers</h1>
        <p>TBD</p>

        <h1 id="organizers">Organizers</h1>
        <p>TBD</p>

        <h1 id="contact">Contact</h1>
        <p>TBD</p>


</body>

</html>

